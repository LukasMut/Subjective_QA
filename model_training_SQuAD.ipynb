{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T18:56:42.481818Z",
     "start_time": "2020-02-04T18:56:37.781901Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "import keras\n",
    "import os\n",
    "import re\n",
    "import torch \n",
    "import transformers\n",
    "import gzip\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import islice\n",
    "from tqdm import trange, tqdm\n",
    "from torch.optim import Adam\n",
    "from transformers import BertTokenizer, BertModel, BertForQuestionAnswering\n",
    "from transformers import AdamW\n",
    "from transformers import get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from models.QAheads import *\n",
    "from models.utils import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T18:56:46.776572Z",
     "start_time": "2020-02-04T18:56:46.772582Z"
    }
   },
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load QA data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T18:56:47.609487Z",
     "start_time": "2020-02-04T18:56:47.153269Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# load SubjQA_data into memory\n",
    "subjqa_data_train = get_data(source='/SubjQA/', split='/train', domain='all')\n",
    "subjqa_data_dev = get_data(source='/SubjQA/', split='/dev', domain='all')\n",
    "subjqa_data_test = get_data(source='/SubjQA/', split='/test', domain='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T18:56:50.111306Z",
     "start_time": "2020-02-04T18:56:49.400894Z"
    }
   },
   "outputs": [],
   "source": [
    "# load SQuAD_data into memory\n",
    "squad_data_train = get_data(\n",
    "                            source='/SQuAD/',\n",
    "                            split='train',\n",
    "                            )\n",
    "\n",
    "#NOTE: we don't have correct answer spans (i.e., start and end positions) for SQuAD dev set\n",
    "#squad_data_dev = get_data(\n",
    "#                          source='/SQuAD/',\n",
    "#                          split='dev',\n",
    "#                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and dev QA examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T18:57:15.733635Z",
     "start_time": "2020-02-04T18:57:15.158952Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: figure out, whether we should use pretrained weights from 'bert-base-cased' or 'bert-base-uncased' model\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "# BERT cannot deal with sequences, where T > 512\n",
    "max_seq_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T18:57:44.832142Z",
     "start_time": "2020-02-04T18:57:39.542767Z"
    }
   },
   "outputs": [],
   "source": [
    "squad_examples_train = create_examples(\n",
    "                                       squad_data_train,\n",
    "                                       is_training=True,\n",
    "                                       )\n",
    "\n",
    "# create train and dev examples from train set only\n",
    "squad_examples_train, squad_examples_dev = split_into_train_and_dev(squad_examples_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T18:59:15.252176Z",
     "start_time": "2020-02-04T18:58:08.887327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b89be051e543609ea51e3ec8b6220b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15228), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "squad_features_train = convert_examples_to_features(\n",
    "                                                    squad_examples_train, \n",
    "                                                    bert_tokenizer,\n",
    "                                                    max_seq_length=max_seq_length,\n",
    "                                                    doc_stride=100,\n",
    "                                                    max_query_length=50,\n",
    "                                                    is_training=True,\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T18:59:58.205113Z",
     "start_time": "2020-02-04T18:59:40.230508Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40a7f42bf304b8397211de8de5c6dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3807), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "squad_features_dev = convert_examples_to_features(\n",
    "                                                squad_examples_dev, \n",
    "                                                bert_tokenizer,\n",
    "                                                max_seq_length=max_seq_length,\n",
    "                                                doc_stride=100,\n",
    "                                                max_query_length=50,\n",
    "                                                is_training=True,\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T19:00:24.063893Z",
     "start_time": "2020-02-04T19:00:23.477438Z"
    }
   },
   "outputs": [],
   "source": [
    "squad_tensor_dataset_train = create_tensor_dataset(\n",
    "                                                   squad_features_train,\n",
    "                                                   evaluate=False,\n",
    "                                                   )\n",
    "\n",
    "squad_tensor_dataset_dev = create_tensor_dataset(\n",
    "                                                 squad_features_dev,\n",
    "                                                 evaluate=False,\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and dev dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T19:00:48.951589Z",
     "start_time": "2020-02-04T19:00:48.947600Z"
    }
   },
   "outputs": [],
   "source": [
    "squad_train_dl = create_batches(\n",
    "                                dataset=squad_tensor_dataset_train,\n",
    "                                batch_size=8,\n",
    "                                split='train',\n",
    "                                )\n",
    "\n",
    "squad_dev_dl = create_batches(\n",
    "                              dataset=squad_tensor_dataset_dev,\n",
    "                              batch_size=8,\n",
    "                              split='eval',\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T19:01:19.310003Z",
     "start_time": "2020-02-04T19:01:13.500479Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecurrentQAHead(\n",
       "  (lstm_encoder): EncoderLSTM(\n",
       "    (lstm): LSTM(1024, 512, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bert_encoder = BertModel.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "bert_encoder = BertModel.from_pretrained('bert-large-cased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "# initialise QA heads\n",
    "linear_head = LinearQAHead()\n",
    "recurrent_head = RecurrentQAHead(max_seq_length=max_seq_length)\n",
    "\n",
    "# cast models to device\n",
    "bert_encoder.to(device)\n",
    "linear_head.to(device)\n",
    "recurrent_head.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-04T18:57:09.778Z"
    }
   },
   "outputs": [],
   "source": [
    "# set current QA head\n",
    "qa_head = recurrent_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-04T18:56:58.935Z"
    }
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "        \"n_epochs\": 3,\n",
    "        \"lr\": 1e-3,\n",
    "        \"warmup_steps\": 100,\n",
    "        \"max_grad_norm\": 10,\n",
    "        \"squad\": True,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-04T18:57:06.489Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(\n",
    "     bert_encoder,\n",
    "     qa_head,\n",
    "     squad_train_dl,\n",
    "     squad_dev_dl,\n",
    "     args,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-04T18:57:01.648Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "          bert_encoder, \n",
    "          qa_head,\n",
    "          train_dl,\n",
    "          val_dl,\n",
    "          args,\n",
    "          ):\n",
    "    \n",
    "    t_total = len(train_dl) * args['n_epochs'] # total number of training steps (i.e., step = iteration)\n",
    "\n",
    "    # NOTE: set pretrained BERT model to eval mode, if we want to evaluate model's performance on SQuAD;\n",
    "    #       if we want to evaluate on SubjQA, pertrained BERT model has to be fine-tuned (--> train mode)\n",
    "    if args[\"squad\"]:\n",
    "        bert_encoder.eval()\n",
    "        print(\"------ BERT model is set to evaluation mode. -------\")\n",
    "        \n",
    "    else:        \n",
    "        bert_optimizer = AdamW(\n",
    "                          bert_encoder.parameters(), \n",
    "                          lr=args['lr'], \n",
    "                          correct_bias=False,\n",
    "                          )\n",
    "    \n",
    "        bert_scheduler = get_linear_schedule_with_warmup(\n",
    "                                                        bert_optimizer, \n",
    "                                                        num_warmup_steps=args[\"warmup_steps\"], \n",
    "                                                        num_training_steps=t_total,\n",
    "                                                        )\n",
    "    \n",
    "    # store loss and accuracy for plotting\n",
    "    train_loss = []\n",
    "    train_accs = []\n",
    "    train_f1s = []\n",
    "    val_accs = []\n",
    "    val_f1s = []\n",
    "    \n",
    "    \n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "        \n",
    "    qa_head_optimizer = Adam(\n",
    "                            qa_head.parameters(), \n",
    "                            lr=args['lr'],\n",
    "                            )\n",
    "\n",
    "\n",
    "    for _ in trange(args['n_epochs'],  desc=\"Epoch\"):\n",
    "\n",
    "        ### Training ###\n",
    "        \n",
    "        # set model to train mode (as opposed to eval mode)\n",
    "        if not args[\"squad\"]:\n",
    "            print(\"------ Fine-tuning pre-trained BERT model AND training of QA head. ------\")\n",
    "            bert_encoder.train()\n",
    "            \n",
    "        else:\n",
    "            print(\"------ Training of QA head. BERT model is frozen. ------\")\n",
    "\n",
    "        # we need to train the QA head for both SQuAD and SubjQA\n",
    "        qa_head.train()\n",
    "\n",
    "        tr_loss, tr_acc = 0, 0\n",
    "        nb_tr_examples, nb_tr_steps = 0, 0\n",
    "        \n",
    "        total_loss = 0\n",
    "\n",
    "\n",
    "        for step, batch in enumerate(tqdm(train_dl, desc=\"Iteration\")):\n",
    "\n",
    "            # add batch to GPU\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # unpack inputs from dataloader            \n",
    "            b_input_ids, b_attn_masks, b_token_type_ids, b_input_lengths, b_start_pos, b_end_pos, b_cls_indexes, _ = batch\n",
    "            \n",
    "            if args[\"squad\"]:\n",
    "                # zero-out gradients\n",
    "                qa_head_optimizer.zero_grad()\n",
    "            else:\n",
    "                bert_optimizer.zero_grad()\n",
    "                bert_scheduler.zero_grad()\n",
    "                qa_head_optimizer.zero_grad()\n",
    "            \n",
    "            bert_reps = bert_encoder(b_input_ids, token_type_ids=b_token_type_ids, attention_mask=b_attn_masks)\n",
    "            \n",
    "            if hasattr(qa_head, 'lstm_encoder'):\n",
    "                start_logits, end_logits = qa_head(bert_reps, b_input_lengths)\n",
    "            else:\n",
    "                start_logits, end_logits = qa_head(bert_reps)\n",
    "            \n",
    "            # start and end loss need to be computed separately\n",
    "            \n",
    "            start_loss = loss_func(start_logits, b_start_pos)\n",
    "            end_loss = loss_func(end_logits, b_end_pos)\n",
    "            \n",
    "            total_loss = (start_loss + end_loss) / 2\n",
    "            print(\"Current loss: {}\".format(total_loss))\n",
    "\n",
    "            train_loss.append(total_loss.item())\n",
    "                \n",
    "            #start_logits = _to_cpu(start_logits)\n",
    "            \n",
    "            #log_probas = F.log_softmax(logits, dim=1).numpy() # or F.softmax(logits).numpy()\n",
    "            #preds_flat = np.argmax(log_probas, axis=1).flatten()\n",
    "\n",
    "\n",
    "            # backpropagation\n",
    "            #start_loss.backward()\n",
    "            #end_loss.backward()\n",
    "            total_loss.backward()\n",
    "            \n",
    "            if args[\"squad\"]:\n",
    "                torch.nn.utils.clip_grad_norm_(qa_head.parameters(), args[\"max_grad_norm\"])\n",
    "                \n",
    "                # update qa_head parameters and take a step using the computed gradient\n",
    "                qa_head_optimizer.step()\n",
    "\n",
    "            else:\n",
    "                torch.nn.utils.clip_grad_norm_(bert_encoder.parameters(), args[\"max_grad_norm\"])\n",
    "                torch.nn.utils.clip_grad_norm_(qa_head.parameters(), args[\"max_grad_norm\"])\n",
    "\n",
    "                # update model parameters and take a step using the computed gradient\n",
    "                bert_optimizer.step()\n",
    "                bert_scheduler.step()\n",
    "                qa_head_optimizer.step()\n",
    "\n",
    "            tr_loss += total_loss.item()\n",
    "            \n",
    "            #tr_acc += tr_acc_current\n",
    "            #tr_f1 += tr_f1_current\n",
    "\n",
    "            nb_tr_examples += b_input_ids.size(0)\n",
    "            nb_tr_steps += 1\n",
    "\n",
    "        print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "        break\n",
    "        \n",
    "        #print(\"Train acc: {}\".format(tr_acc/nb_tr_steps))\n",
    "        #print(\"Train f1: {}\".format(tr_f1/nb_tr_steps))\n",
    "        \n",
    "        #train_accs.append(tr_acc/nb_tr_steps)\n",
    "        #train_f1s.append(tr_f1/nb_tr_steps)\n",
    "\n",
    "        \n",
    "\n",
    "        ### Validation ###\n",
    "\n",
    "        # set models to eval mode to evaluate loss on the validation set\n",
    "        if not args[\"squad\"]:\n",
    "            bert_encoder.eval()\n",
    "            \n",
    "        qa_head.eval()\n",
    "\n",
    "        eval_acc, eval_f1 = 0, 0\n",
    "        nb_eval_steps = 0\n",
    "\n",
    "        for batch in val_dl:\n",
    "\n",
    "            # add batch to GPU\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # unpack inputs from dataloader\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "            # telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "\n",
    "            with torch.no_grad():\n",
    "                if model_name == 'DistilBERT':\n",
    "                    logits = model(b_input_ids, attention_mask=b_input_mask)\n",
    "                else:\n",
    "                    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "            # move logits and labels to CPU to compute NumPy operations\n",
    "            logits = logits[0].detach().cpu()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "            \n",
    "            log_probas = F.log_softmax(logits, dim=1).numpy() # or F.softmax(logits).numpy()\n",
    "            preds_flat = np.argmax(log_probas, axis=1).flatten()\n",
    "\n",
    "            tmp_eval_acc = accuracy(preds_flat, label_ids)\n",
    "            tmp_eval_f1 = f1(preds_flat, label_ids)\n",
    "\n",
    "            eval_acc += tmp_eval_acc\n",
    "            eval_f1 += tmp_eval_f1\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "        print(\"Val acc: {}\".format(eval_acc/nb_eval_steps))\n",
    "        print(\"Val f1: {}\".format(eval_f1/nb_eval_steps))\n",
    "        val_accs.append(eval_acc/nb_eval_steps)\n",
    "        val_f1s.append(eval_f1/nb_eval_steps)\n",
    "        \n",
    "    return train_loss, train_accs, train_f1s, val_accs, val_f1s, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T14:26:02.646693Z",
     "start_time": "2020-02-03T14:26:02.631069Z"
    }
   },
   "outputs": [],
   "source": [
    "support, question = \"Who was Jim Henson?\", \"Jim Henson was a nice puppet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T14:26:06.189222Z",
     "start_time": "2020-02-03T14:26:06.185213Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(support, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T11:31:59.279076Z",
     "start_time": "2020-02-03T11:31:59.274088Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_dict = tokenizer.encode_plus(support, question, max_length=19, pad_to_max_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T11:32:21.237260Z",
     "start_time": "2020-02-03T11:32:21.233246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_dict['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T14:26:11.063555Z",
     "start_time": "2020-02-03T14:26:11.053853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] who was jim henson? [SEP] jim henson was a nice puppet [SEP]'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T14:26:17.041808Z",
     "start_time": "2020-02-03T14:26:16.871864Z"
    }
   },
   "outputs": [],
   "source": [
    "token_type_ids = [0 if i <= input_ids.index(102) else 1 for i in range(len(input_ids))]\n",
    "bert_outputs = bert_encoder(torch.tensor([input_ids]), token_type_ids=torch.tensor([token_type_ids]))\n",
    "start_scores, end_scores = linear_head(bert_outputs)\n",
    "\n",
    "all_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "answer = ' '.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1])\n",
    "\n",
    "#assert answer == \"a nice puppet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T14:26:19.955818Z",
     "start_time": "2020-02-03T14:26:19.933131Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'who',\n",
       " 'was',\n",
       " 'jim',\n",
       " 'henson',\n",
       " '?',\n",
       " '[SEP]',\n",
       " 'jim',\n",
       " 'henson',\n",
       " 'was',\n",
       " 'a',\n",
       " 'nice',\n",
       " 'puppet',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T14:26:53.048321Z",
     "start_time": "2020-02-03T14:26:53.043301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3921,  0.7497,  0.8149,  0.7072,  0.1412,  0.7454,  0.3920,  0.6636,\n",
       "         0.1638,  0.5663,  0.5980, -0.2040, -0.1426,  0.3924],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T14:26:27.278089Z",
     "start_time": "2020-02-03T14:26:27.274099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
